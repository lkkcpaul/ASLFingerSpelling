{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Create tfrecords that's split into 6 folds.\n\nInclude only landmarks of left/right hand, left/right chest, and lips.\n\nPhrase is encoded into index as int32.\n\nSince there are duplicate phrases signed by different people, split the data by phrase such that the multiple videos of the same phrase are stored in the same fold.","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport tensorflow as tf\nimport json\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nimport json\nwith open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n    char2id = json.load(f)\nid2char = {i:char for char,i in char2id.items()}","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-24T06:49:12.317427Z","iopub.execute_input":"2023-08-24T06:49:12.318568Z","iopub.status.idle":"2023-08-24T06:49:24.722528Z","shell.execute_reply.started":"2023-08-24T06:49:12.318506Z","shell.execute_reply":"2023-08-24T06:49:24.721193Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/asl-fingerspelling/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T06:49:24.725224Z","iopub.execute_input":"2023-08-24T06:49:24.727324Z","iopub.status.idle":"2023-08-24T06:49:24.958058Z","shell.execute_reply.started":"2023-08-24T06:49:24.727270Z","shell.execute_reply":"2023-08-24T06:49:24.957113Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                              path  file_id  sequence_id  participant_id  \\\n0  train_landmarks/5414471.parquet  5414471   1816796431             217   \n1  train_landmarks/5414471.parquet  5414471   1816825349             107   \n2  train_landmarks/5414471.parquet  5414471   1816909464               1   \n3  train_landmarks/5414471.parquet  5414471   1816967051              63   \n4  train_landmarks/5414471.parquet  5414471   1817123330              89   \n\n                      phrase  \n0               3 creekhouse  \n1            scales/kuhaylah  \n2        1383 william lanier  \n3          988 franklin lane  \n4  6920 northeast 661st road  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>file_id</th>\n      <th>sequence_id</th>\n      <th>participant_id</th>\n      <th>phrase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816796431</td>\n      <td>217</td>\n      <td>3 creekhouse</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816825349</td>\n      <td>107</td>\n      <td>scales/kuhaylah</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816909464</td>\n      <td>1</td>\n      <td>1383 william lanier</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816967051</td>\n      <td>63</td>\n      <td>988 franklin lane</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1817123330</td>\n      <td>89</td>\n      <td>6920 northeast 661st road</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"RIGHT_HAND_COLS = [f'{c}_right_hand_{i}' for i in range(21) for c in 'xyz']\nLEFT_HAND_COLS = [f'{c}_left_hand_{i}' for i in range(21) for c in 'xyz']\nLIP_COLS = [f'{c}_face_{i}' for i in \n            [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n            291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n            78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n            95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n            ] for c in 'xyz']\nLPOSE_COLS = [f'{c}_pose_{i}' for i in [11, 13, 15, 17, 19, 21] for c in 'xyz']\nRPOSE_COLS = [f'{c}_pose_{i}' for i in [12, 14, 16, 18, 20, 22] for c in 'xyz']\nLIST_COLS_LIST = [RIGHT_HAND_COLS, LEFT_HAND_COLS, LIP_COLS, LPOSE_COLS, RPOSE_COLS]\nSEL_COLS = RIGHT_HAND_COLS + LEFT_HAND_COLS + LIP_COLS + LPOSE_COLS + RPOSE_COLS\n\nf = open('/kaggle/input/asl-fingerspelling/character_to_prediction_index.json')\nchar2id = json.load(f)\nf.close()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T06:49:24.959533Z","iopub.execute_input":"2023-08-24T06:49:24.960906Z","iopub.status.idle":"2023-08-24T06:49:24.973590Z","shell.execute_reply.started":"2023-08-24T06:49:24.960854Z","shell.execute_reply":"2023-08-24T06:49:24.972406Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"phrase_df = pd.DataFrame({'phrase':df.phrase.unique()})\nphrase_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:10:37.520462Z","iopub.execute_input":"2023-08-24T05:10:37.520944Z","iopub.status.idle":"2023-08-24T05:10:37.550041Z","shell.execute_reply.started":"2023-08-24T05:10:37.520905Z","shell.execute_reply":"2023-08-24T05:10:37.549217Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                      phrase\n0               3 creekhouse\n1            scales/kuhaylah\n2        1383 william lanier\n3          988 franklin lane\n4  6920 northeast 661st road","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>phrase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3 creekhouse</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scales/kuhaylah</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1383 william lanier</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>988 franklin lane</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6920 northeast 661st road</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(len(phrase_df))\nprint(df.phrase.nunique())","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:11:11.116484Z","iopub.execute_input":"2023-08-24T05:11:11.116861Z","iopub.status.idle":"2023-08-24T05:11:11.136359Z","shell.execute_reply.started":"2023-08-24T05:11:11.116832Z","shell.execute_reply":"2023-08-24T05:11:11.135053Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"46478\n46478\n","output_type":"stream"}]},{"cell_type":"code","source":"phrase_df['fold'] = -1\nkfold = KFold(n_splits=6, shuffle=True, random_state=42)\nfor fold_idx, (train_idx, val_idx) in enumerate(kfold.split(phrase_df.index)):\n    phrase_df.loc[val_idx,'fold'] = fold_idx\nassert (phrase_df['fold']==-1).sum()==0\nphrase_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:12:17.581053Z","iopub.execute_input":"2023-08-24T05:12:17.582085Z","iopub.status.idle":"2023-08-24T05:12:17.606803Z","shell.execute_reply.started":"2023-08-24T05:12:17.582045Z","shell.execute_reply":"2023-08-24T05:12:17.605608Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                      phrase  fold\n0               3 creekhouse     1\n1            scales/kuhaylah     0\n2        1383 william lanier     4\n3          988 franklin lane     3\n4  6920 northeast 661st road     0\n5            www.freem.ne.jp     4\n6     https://jsi.is/hukuoka     2\n7       239613 stolze street     0\n8               242-197-6202     2\n9  271097 bayshore boulevard     5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>phrase</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3 creekhouse</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scales/kuhaylah</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1383 william lanier</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>988 franklin lane</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6920 northeast 661st road</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>www.freem.ne.jp</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>https://jsi.is/hukuoka</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>239613 stolze street</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>242-197-6202</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>271097 bayshore boulevard</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.merge(phrase_df,on='phrase')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:12:46.181425Z","iopub.execute_input":"2023-08-24T05:12:46.181836Z","iopub.status.idle":"2023-08-24T05:12:46.248253Z","shell.execute_reply.started":"2023-08-24T05:12:46.181795Z","shell.execute_reply":"2023-08-24T05:12:46.247125Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                 path     file_id  sequence_id  \\\n0     train_landmarks/5414471.parquet     5414471   1816796431   \n1     train_landmarks/5414471.parquet     5414471   1816825349   \n2   train_landmarks/175396851.parquet   175396851    105856225   \n3     train_landmarks/5414471.parquet     5414471   1816909464   \n4  train_landmarks/1134756332.parquet  1134756332    137139884   \n\n   participant_id               phrase  fold  \n0             217         3 creekhouse     1  \n1             107      scales/kuhaylah     0  \n2             121      scales/kuhaylah     0  \n3               1  1383 william lanier     4  \n4             236  1383 william lanier     4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>file_id</th>\n      <th>sequence_id</th>\n      <th>participant_id</th>\n      <th>phrase</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816796431</td>\n      <td>217</td>\n      <td>3 creekhouse</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816825349</td>\n      <td>107</td>\n      <td>scales/kuhaylah</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmarks/175396851.parquet</td>\n      <td>175396851</td>\n      <td>105856225</td>\n      <td>121</td>\n      <td>scales/kuhaylah</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_landmarks/5414471.parquet</td>\n      <td>5414471</td>\n      <td>1816909464</td>\n      <td>1</td>\n      <td>1383 william lanier</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_landmarks/1134756332.parquet</td>\n      <td>1134756332</td>\n      <td>137139884</td>\n      <td>236</td>\n      <td>1383 william lanier</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"write_options = tf.io.TFRecordOptions(compression_type='GZIP', compression_level=9)\n\ndef write_fold(df, file_name):\n    num_samples = 0\n    with tf.io.TFRecordWriter(file_name,options=write_options) as file_writer:\n        for file in tqdm(df.path.unique()):\n            pq_df = pd.read_parquet('/kaggle/input/asl-fingerspelling/'+file,\n                                    columns = SEL_COLS)\n            for sid in df[df['path']==file]['sequence_id'].unique():\n\n                phrase = df[df['sequence_id']==sid]['phrase'].iloc[0]\n                encoded_phrase = tf.constant([char2id[char] for char in phrase], dtype=tf.int32) # didn't specify dtype\n                lm_df = pq_df[pq_df.index==sid]\n                \n                rh_np = lm_df[RIGHT_HAND_COLS].values.reshape(-1,len(RIGHT_HAND_COLS)//3, 3)\n                lh_np = lm_df[LEFT_HAND_COLS].values.reshape(-1,len(LEFT_HAND_COLS)//3, 3)\n                rpose_np = lm_df[RPOSE_COLS].values.reshape(-1,len(RPOSE_COLS)//3, 3)\n                lpose_np = lm_df[LPOSE_COLS].values.reshape(-1,len(LPOSE_COLS)//3, 3)\n                lip_np = lm_df[LIP_COLS].values.reshape(-1,len(LIP_COLS)//3, 3)\n\n                record_bytes = tf.train.Example(features = tf.train.Features(feature ={\n                    'right_hand':tf.train.Feature(bytes_list=tf.train.BytesList(value=[rh_np.tobytes()])),\n                    'left_hand':tf.train.Feature(bytes_list=tf.train.BytesList(value=[lh_np.tobytes()])),\n                    'left_pose':tf.train.Feature(bytes_list=tf.train.BytesList(value=[lpose_np.tobytes()])),\n                    'right_pose':tf.train.Feature(bytes_list=tf.train.BytesList(value=[rpose_np.tobytes()])),\n                    'lip':tf.train.Feature(bytes_list=tf.train.BytesList(value=[lip_np.tobytes()])),\n                    'encoded_phrase':tf.train.Feature(int64_list=tf.train.Int64List(value=encoded_phrase)),\n                    })).SerializeToString()\n\n                file_writer.write(record_bytes)\n                num_samples+=1\n    print(file_name,f'has {num_samples} samples')","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:14:43.818556Z","iopub.execute_input":"2023-08-24T05:14:43.818954Z","iopub.status.idle":"2023-08-24T05:14:43.831244Z","shell.execute_reply.started":"2023-08-24T05:14:43.818924Z","shell.execute_reply":"2023-08-24T05:14:43.830305Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for fold in range(6):\n    write_fold(df[df['fold']==fold], f'fold{fold}.tfrecords')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the number of samples that are completely nan on right hand and left hand\nno_good_frame=0\nfor file in tqdm(df.path.unique()):\n    pq_df = pd.read_parquet('/kaggle/input/asl-fingerspelling/'+file,\n                            columns = RIGHT_HAND_COLS+LEFT_HAND_COLS)\n    for sid in df[df['path']==file]['sequence_id'].unique():\n        lm_df = pq_df[pq_df.index==sid]\n        lm = lm_df.values\n        if np.sum(np.any(~np.isnan(lm),axis=1)) == 0:\n            no_good_frame+=1\n        \nprint(no_good_frame)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T06:59:52.428339Z","iopub.execute_input":"2023-08-24T06:59:52.428837Z","iopub.status.idle":"2023-08-24T07:00:39.712096Z","shell.execute_reply.started":"2023-08-24T06:59:52.428798Z","shell.execute_reply":"2023-08-24T07:00:39.710601Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/68 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e2f10ad5fa24a7a869a4f38e30089e9"}},"metadata":{}},{"name":"stdout","text":"0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check the maximum number of frames after dropping the nan frames\nmax_good_frame = 0\nfor file in tqdm(df.path.unique()):\n    pq_df = pd.read_parquet('/kaggle/input/asl-fingerspelling/'+file,\n                            columns = RIGHT_HAND_COLS+LEFT_HAND_COLS)\n    for sid in df[df['path']==file]['sequence_id'].unique():\n        lm_df = pq_df[pq_df.index==sid]\n        lm = lm_df.values\n        max_good_frame = max(max_good_frame,np.sum(np.any(~np.isnan(lm),axis=1)))\n        \nprint(max_good_frame)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-24T06:53:35.005393Z","iopub.execute_input":"2023-08-24T06:53:35.005922Z","iopub.status.idle":"2023-08-24T06:54:55.997313Z","shell.execute_reply.started":"2023-08-24T06:53:35.005879Z","shell.execute_reply":"2023-08-24T06:54:55.995759Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/68 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5293e843d4ff4f0d9a24bfe86097401f"}},"metadata":{}},{"name":"stdout","text":"598\n","output_type":"stream"}]}]}