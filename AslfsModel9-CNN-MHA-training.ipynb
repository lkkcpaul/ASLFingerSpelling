{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport tensorflow as tf\nimport json\nfrom tensorflow.keras import layers\nimport tensorflow.keras.mixed_precision as mixed_precision\nimport matplotlib.pyplot as plt\nimport tensorflow_addons as tfa\nimport gc\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-24T17:47:10.339810Z","iopub.execute_input":"2023-08-24T17:47:10.340272Z","iopub.status.idle":"2023-08-24T17:47:10.347381Z","shell.execute_reply.started":"2023-08-24T17:47:10.340238Z","shell.execute_reply":"2023-08-24T17:47:10.346442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\nseed_everything()\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=\"local\") # \"local\" for 1VM TPU\n    strategy = tf.distribute.TPUStrategy(tpu)\n    print(\"on TPU\")\n    N_REPLICAS = strategy.num_replicas_in_sync\n    print(\"REPLICAS: \", N_REPLICAS)\n    \nexcept:\n    strategy = tf.distribute.get_strategy()\n    N_REPLICAS = 1","metadata":{"execution":{"iopub.status.busy":"2023-08-24T17:23:45.627373Z","iopub.execute_input":"2023-08-24T17:23:45.628297Z","iopub.status.idle":"2023-08-24T17:23:45.955880Z","shell.execute_reply.started":"2023-08-24T17:23:45.628250Z","shell.execute_reply":"2023-08-24T17:23:45.954447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_subset = None # Size of subset of data to use, for faster debugging. Set None for all data.\n# device='CPU' This is automated now\nval_fold = 0 # Choose from 0th-5th fold as the validation\nmodel_output_name = 'modelv9'  #Specify the name of the output model\nverbose = 2  # (0): No output. (1): progress bar. (2): One line per epoch (Recommended for saving a new version)\n\n# parameters of model architecture\nnum_heads = 2      # Number of attention heads\nhead_size = 128    # Dimension of each head\nkernel_size = 4   # Kernel size of local attention\nDIM = num_heads*head_size  # This will be the dimension of the embedding and attention\nCNN_ksize = int(np.sqrt(DIM))\ndropout = 0.33 \nnum_enc_layers = 8    # Number of attention blocks for input and output \nnum_dec_layers = 4\n# Parameters for training\nepochs = 300\nlr = 3e-4*N_REPLICAS\nlr_min = 1e-6 # minimum learning rate over time\nwarmup_epochs = 5\nresume_epoch = 0 # Suppose we want to resume training\ndecay_epochs = 200 #scale at which the lr decays. \ndecay_type = 'cosine'\nawp_start_epoch = 20\nbatch_size = 32*N_REPLICAS\nearly_stop_patience = 10  # If the validation error doesn't improve in this many epochs, stop early\n#dropout_start_epoch = 10\n#Parameters of data preprocessing and augmentation\n# Set to none for no augmentation\nrot_deg = (-20., 20.) \nshift = (-0.1, 0.1)\nscale = (0.8, 1.2)\nshear = (-0.2, 0.2)\n#time_dilation = (0.8, 1.2)\ntime_mask_prob = 0.02\n\n# Parameters of structure of data\nNUM_POINTS = 42\nCHANNELS = NUM_POINTS*6\nMAX_INPUT_LEN = 600 #Because we drop nan frames\nMAX_OUTPUT_LEN = 31+2 #+2 for the start and end token \n\nf = open('/kaggle/input/asl-fingerspelling/character_to_prediction_index.json')\nchar2id = json.load(f)\nf.close()\nstart_token = '\\t'\nstart_token_idx = 59\nend_token = '\\n'\nend_token_idx = 60\npad_token = 'P'\nTKPAD = 61 \nchar2id[start_token] = start_token_idx   #Use as start token\nchar2id[end_token]= end_token_idx   #Use as end token\nchar2id[pad_token] = TKPAD\nid2char = {char2id[c]:c for c in char2id.keys()}\nVOCAB_SIZE = len(char2id) #includes start, end, pad tokens.\nLMPAD = -100.0\n","metadata":{"execution":{"iopub.status.busy":"2023-08-24T17:47:16.464349Z","iopub.execute_input":"2023-08-24T17:47:16.464782Z","iopub.status.idle":"2023-08-24T17:47:16.481152Z","shell.execute_reply.started":"2023-08-24T17:47:16.464748Z","shell.execute_reply":"2023-08-24T17:47:16.480004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_files = [f'/kaggle/input/aslfstfrecords3/fold{i}.tfrecords' for i in range(6)]\nval_files = train_files[val_fold]\ndel train_files[val_fold]\n\nnum_samples_per_file = [11155, 11230, 11141, 11237, 11267, 11178]\ntotal_num_samples = sum(num_samples_per_file)\nval_num_samples = num_samples_per_file[val_fold]\ntrain_num_samples = total_num_samples - val_num_samples\nsteps_per_epoch = int(np.ceil(train_num_samples/batch_size))\nval_steps = int(np.ceil(val_num_samples/batch_size))\n\nAUTO = tf.data.AUTOTUNE\n\n#decode single record\ndef decode_record(record_bytes):\n    features = tf.io.parse_single_example(record_bytes,{\n                                          'right_hand':tf.io.FixedLenFeature([],tf.string),\n                                          'left_hand':tf.io.FixedLenFeature([],tf.string),\n                                          'left_pose':tf.io.FixedLenFeature([],tf.string),\n                                          'right_pose':tf.io.FixedLenFeature([],tf.string),\n                                          'lip':tf.io.FixedLenFeature([],tf.string),\n                                          'encoded_phrase':tf.io.VarLenFeature(tf.int64),\n                                        })\n    features['encoded_phrase'] = tf.cast(tf.sparse.to_dense(features['encoded_phrase']),tf.int32)\n    features['right_hand'] = tf.reshape(tf.io.decode_raw(features['right_hand'], tf.float32), (-1,21,3))\n    features['left_hand'] = tf.reshape(tf.io.decode_raw(features['left_hand'], tf.float32), (-1,21,3))\n    #features['left_pose'] = tf.reshape(tf.io.decode_raw(features['left_pose'], tf.float32), (-1,6,3))\n    #features['right_pose'] = tf.reshape(tf.io.decode_raw(features['right_pose'], tf.float32), (-1,6,3))\n    #features['lip'] = tf.reshape(tf.io.decode_raw(features['lip'], tf.float32), (-1,40,3))\n    \n    return tf.concat([features['right_hand'][:,:,:2], features['left_hand'][:,:,:2]],axis=1), features['encoded_phrase']\n\ndef tf_nan_mean(x, axis=0, keepdims=False):\n    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis, keepdims=keepdims) / tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis, keepdims=keepdims)\n\ndef tf_nan_std(x, center=None, axis=0, keepdims=False):\n    if center is None:\n        center = tf_nan_mean(x, axis=axis,  keepdims=True)\n    d = x - center\n    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis, keepdims=keepdims))\n\ndef normalize(coord, text):\n    coord = coord-tf_nan_mean(coord, axis=(0,1))\n    coord = coord/tf_nan_std(coord,axis=(0,1,2))\n    return coord, text\n\n  \n# Some augmentation functions.\ndef spatial_affine(coord, scale = scale, shear = shear,\n                   shift = shift, degree = rot_deg):\n    if scale:\n        coord *= tf.random.uniform((),*scale)\n        \n    if shear:\n        if tf.random.uniform(())<0.5:\n            shear_x = 0.\n            shear_y = tf.random.uniform((),*shear)\n        else:\n            shear_y = 0.\n            shear_x = tf.random.uniform((),*shear)\n        shear_mat = tf.identity([[1., shear_x],\n                                 [shear_y, 1.]])\n        coord = coord @ shear_mat\n        \n    if degree:\n        rad = tf.random.uniform((),*degree)*np.pi/180\n        c = tf.math.cos(rad)\n        s = tf.math.sin(rad)\n        rot_mat = tf.identity([[c, s],\n                               [-s, c]])\n        coord = coord@rot_mat\n    if shift:\n        coord += tf.random.uniform((2,),*shift)[None,None,:]\n    return coord\n    \ndef temporal_mask(coord, rate=time_mask_prob, mask_value = float('nan')):\n    T = tf.shape(coord)[0]\n    mask = tf.random.uniform((T,))<rate\n    coord = tf.where(mask[:,None,None], mask_value, coord)\n    return coord\n\ndef flip_rl(coord):\n    right = coord[:,:21,:]\n    left = coord[:,21:,:]\n    axis_to_flip = tf.constant([True,False])[None,None,:]\n    right = tf.where(axis_to_flip,-right,right)\n    left = tf.where(axis_to_flip,-left,left)\n    return tf.concat([left,right],axis=1) #Fix bug\n\ndef augment_fn(coord,text,always=False):\n    \n    if tf.random.uniform(())<0.5:\n        coord = flip_rl(coord)\n\n    if always or tf.random.uniform(())<0.8:\n        coord = spatial_affine(coord)\n    \n    if always or tf.random.uniform(())<0.5:\n        coord = temporal_mask(coord)\n    \n    return coord,text\n\ndef format_sample(coord,text):\n    num_points = tf.shape(coord)[1]\n    coord = tf.reshape(coord,(-1,2*num_points))\n    \n    dx = tf.cond(tf.shape(coord)[0]>1,\n                 lambda:tf.pad(coord[1:,:] - coord[:-1,:], [[0,1],[0,0]]),\n                 lambda:tf.fill(tf.shape(coord), np.nan))   \n    dx2 = tf.cond(tf.shape(coord)[0]>2,\n             lambda:tf.pad(coord[2:,:] - coord[:-2,:], [[0,2],[0,0]]),\n             lambda:tf.fill(tf.shape(coord), np.nan))\n\n    coord = tf.concat([coord,dx,dx2],axis=1)\n    \n    coord = tf.boolean_mask(coord, ~tf.reduce_all(tf.math.is_nan(coord),axis=1)) #Drop if it's all nan. \n    #coord = tf.where(tf.reduce_all(tf.math.is_nan(coord),axis=1,keepdims=True), LMPAD, coord)\n    coord = tf.where(tf.math.is_nan(coord), 0., coord)\n    \n    text = tf.concat([tf.constant([start_token_idx]), text, tf.constant([end_token_idx])],axis=0)\n    \n    return coord,text\n\ndef context_target_split(coord,text):\n    return (coord,text[:,:-1]), text[:,1:]\n\ndef preprocess(ds, augment=False,repeat=False,shuffle=False):\n    ds = ds.map(decode_record, AUTO) #returns right_hand, left_hand, encoded_phrase, where lm are in shape (frames, points, xy)\n    ds = ds.map(normalize, AUTO)\n    if augment:\n        ds = ds.map(augment_fn, AUTO)\n    ds = ds.map(format_sample, AUTO) # ds returns right,left,text with nans filled in.\n    \n    if repeat:\n        ds = ds.repeat()\n    if shuffle:\n        ds = ds.shuffle(8191)\n        options = tf.data.Options()\n        options.experimental_deterministic = (False)\n        ds = ds.with_options(options)\n        \n    ds = ds.padded_batch(batch_size, \n                         padding_values = (LMPAD,TKPAD), \n                         padded_shapes = ([MAX_INPUT_LEN,6*NUM_POINTS],[MAX_OUTPUT_LEN]))\n    \n    ds = ds.map(context_target_split, AUTO)\n    ds = ds.prefetch(AUTO)\n    return ds\n   \ntrain_ds = tf.data.TFRecordDataset(train_files, num_parallel_reads=AUTO,\n                                    compression_type='GZIP')\nval_ds = tf.data.TFRecordDataset(val_files, num_parallel_reads=AUTO,\n                                    compression_type='GZIP')\n\nif data_subset:\n    train_ds = train_ds.take(data_subset)\n    val_ds = val_ds.take(data_subset//5)\n    \ntrain_ds = preprocess(train_ds, augment=True, repeat=True, shuffle=True)\nval_ds = preprocess(val_ds)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T17:23:45.981703Z","iopub.execute_input":"2023-08-24T17:23:45.982148Z","iopub.status.idle":"2023-08-24T17:23:48.012560Z","shell.execute_reply.started":"2023-08-24T17:23:45.982116Z","shell.execute_reply":"2023-08-24T17:23:48.011431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for s in train_ds:\n    (coord, context), label = s\n    print('inpu coordinate shape',coord.shape)\n    print('input context shape', context.shape)\n    print('label shape', label.shape)\n    print('2 Samples of context:')\n    print(context[:2])\n    print('2 Samples of label:')\n    print(label[:2])\n    break","metadata":{"execution":{"iopub.status.busy":"2023-08-24T17:23:48.014264Z","iopub.execute_input":"2023-08-24T17:23:48.014635Z","iopub.status.idle":"2023-08-24T17:24:01.489328Z","shell.execute_reply.started":"2023-08-24T17:23:48.014604Z","shell.execute_reply":"2023-08-24T17:24:01.488288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ECA(tf.keras.layers.Layer):\n    def __init__(self, kernel_size=5, **kwargs):\n        super().__init__(**kwargs)\n        self.supports_masking = True\n        self.kernel_size = kernel_size\n        self.conv = tf.keras.layers.Conv1D(1, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=False)\n\n    def call(self, inputs, mask=None):\n        nn = tf.keras.layers.GlobalAveragePooling1D()(inputs, mask=mask)\n        nn = tf.expand_dims(nn, -1)\n        nn = self.conv(nn)\n        nn = tf.squeeze(nn, -1)\n        nn = tf.nn.sigmoid(nn)\n        nn = nn[:,None,:]\n        return inputs * nn\n\nclass CausalDWConv1D(tf.keras.layers.Layer):\n    def __init__(self, \n        kernel_size=CNN_ksize,\n        dilation_rate=1,\n        use_bias=False,\n        depthwise_initializer='glorot_uniform',\n        name='', **kwargs):\n        super().__init__(name=name,**kwargs)\n        self.causal_pad = tf.keras.layers.ZeroPadding1D((dilation_rate*(kernel_size-1),0),name=name + '_pad')\n        self.dw_conv = tf.keras.layers.DepthwiseConv1D(\n                            kernel_size,\n                            strides=1,\n                            dilation_rate=dilation_rate,\n                            padding='valid',\n                            use_bias=use_bias,\n                            depthwise_initializer=depthwise_initializer,\n                            name=name + '_dwconv')\n        self.supports_masking = True\n        \n    def call(self, inputs):\n        x = self.causal_pad(inputs)\n        x = self.dw_conv(x)\n        return x\n\nclass Conv1DBlock(layers.Layer):\n    def __init__(self,channel_size=DIM,kernel_size=CNN_ksize, dilation_rate=1, drop_rate=dropout,\n          expand_ratio=2, se_ratio=0.25, activation='swish', **kwargs):\n        super().__init__(**kwargs)\n        self.expand = layers.Dense(channel_size*expand_ratio)\n        self.dwconv = CausalDWConv1D(kernel_size,dilation_rate=dilation_rate,use_bias=False)\n        self.bn = layers.BatchNormalization(momentum=0.95)\n        self.eca = ECA()\n        self.proj = layers.Dense(channel_size,use_bias=True)\n        self.drop = layers.Dropout(drop_rate, noise_shape=(None,1,1))\n        self.add = layers.Add()\n        self.supports_masking=True\n    '''\n    efficient conv1d block, @hoyso48\n    '''\n    # Expansion phase\n    def call(self, x):\n        bypass = x\n        x = self.expand(x)\n        # Depthwise Convolution\n        x = self.dwconv(x)\n        x = self.bn(x)\n        x = self.eca(x)\n        x = self.proj(x)\n        x = self.drop(x)\n        x = self.add([x,bypass])\n        return x   \n\nclass TokenEmbedding(layers.Layer):\n    \"\"\"Input: (*, seq_len). Output: (*, seq_len, embedding_dim)\n    Input 0 will be masked.\n    CHECK: Can we speed up by making pos a constant tensor?\"\"\"\n    \n    def __init__(self, vocab_size=VOCAB_SIZE, max_len=MAX_OUTPUT_LEN, embed_dim=DIM, \n                 pad_value=TKPAD, dropout=dropout, **kwargs):\n        super().__init__(**kwargs)\n        self.tok_emb = layers.Embedding(vocab_size, embed_dim)\n        self.pos_emb = layers.Embedding(max_len, embed_dim)\n        self.drop = layers.Dropout(dropout)\n        self.pad = pad_value\n        self.scale = tf.math.sqrt(tf.cast(embed_dim,tf.float32))\n        self.pos = tf.range(max_len)[None,:]\n        self.ln = layers.LayerNormalization(center=False)\n        \n    def call(self, x):\n        #B = tf.shape(x)[0]\n        T = tf.shape(x)[1]\n        x = self.tok_emb(x)\n        x *= self.scale # Set the relative scale of the token and position embeddng\n        pos = self.pos_emb(self.pos[:,:T])\n        x = x+pos\n        x = self.drop(x)\n        x = self.ln(x)\n        return x\n    \n    def compute_mask(self,x, mask=None):\n        new_mask = x!=self.pad\n        if mask:\n            new_mask = new_mask & mask\n        return new_mask\n    \n\nclass CoordEmbedding(layers.Layer):\n    \"\"\"Input: (*, seq_len, channels). Output: (*, seq_len, embedding_dim)\n    Also creates mask for any time frame that includes mask_value\"\"\"\n    \n    def __init__(self, max_len=MAX_INPUT_LEN, embed_dim=DIM, dropout=dropout, mask_value=LMPAD, **kwargs):\n        super().__init__(**kwargs)\n        \n        self.masking = layers.Masking(mask_value=mask_value)\n        self.emb = layers.Dense(embed_dim) #bias or not is debatable\n        self.bn = layers.BatchNormalization(momentum=0.95)\n        self.convs = [Conv1DBlock(embed_dim,kernel_size=CNN_ksize,drop_rate=dropout) for _ in range(3)]\n        \n        self.pos_emb = layers.Embedding(max_len, embed_dim)\n        self.drop = layers.Dropout(dropout)\n        self.scale = tf.math.sqrt(tf.cast(embed_dim,tf.float32))\n        self.pad = mask_value\n        self.pos = tf.range(max_len)[None,:]\n        self.ln = layers.LayerNormalization(center=False)\n        \n    def call(self, x):\n        #B = tf.shape(x)[0]\n        T = tf.shape(x)[1]\n        x = self.masking(x)\n        x = self.emb(x)\n        x = self.bn(x)\n        \n        for conv in self.convs:\n            x = conv(x)\n        \n        x *= self.scale  # Set the relative scale of the token and position embeddng\n        pos = self.pos_emb(self.pos[:,:T])\n        x = x + pos\n        x = self.drop(x)\n        x = self.ln(x)\n        return x\n    \n    def compute_mask(self, x, mask=None):\n        new_mask = tf.reduce_all(x!=self.pad, axis=-1)\n        if mask:\n            new_mask = new_mask & mask\n        return new_mask\n    \nclass MLP(layers.Layer):\n    \"\"\"input and output are the same shape. \n    Dense layer to 4x the hidden dim and then dense layer back to 1x hidden dim\"\"\"\n    def __init__(self, input_dim=DIM, dropout=dropout, bias=False, **kwargs):\n        super().__init__(**kwargs)\n        self.c_fc = layers.Dense(4*input_dim, use_bias=bias, activation='gelu')\n        self.c_proj = layers.Dense(input_dim, use_bias=bias)\n        self.drop = layers.Dropout(dropout) # CHECK noise_shape later\n        self.supports_masking=True\n        \n    def call(self, x):\n        x = self.c_fc(x)\n        x = self.c_proj(x)\n        x = self.drop(x)\n        return x\n\nclass EncoderTransformerBlock(layers.Layer):\n    def __init__(self,head_size=head_size, num_heads=num_heads, dropout=dropout, kernel_size=kernel_size, num_local=2, **kwargs):\n        super().__init__(**kwargs)\n        self.num_local = num_local\n        self.lns = [layers.LayerNormalization(center=False) for _ in range(self.num_local)]\n        self.adds = [layers.Add() for _ in range(self.num_local)]\n        self.local_atts = [layers.MultiHeadAttention(num_heads,head_size,dropout=dropout,use_bias=False) for _ in range(self.num_local)]\n        self.local_mask = tf.cast(tf.linalg.band_part(\n                        tf.ones((MAX_INPUT_LEN,MAX_INPUT_LEN)), kernel_size-1, 0), tf.bool)\n        \n        self.ln2 = layers.LayerNormalization(center=False)\n        self.add2 = layers.Add()\n        self.global_att = layers.MultiHeadAttention(num_heads,head_size,dropout=dropout,use_bias=False)\n        \n        self.ln3 = layers.LayerNormalization(center=False)\n        self.mlp = MLP(head_size*num_heads)\n        self.add3 = layers.Add()\n        \n        self.support_masking=True   \n    \n    def call(self,x):\n        T = tf.shape(x)[1]\n        for i in range(self.num_local):\n            bypass = x\n            x = self.lns[i](x)\n            x = self.local_atts[i](x,x, attention_mask = self.local_mask[:T,:T])\n            x = self.adds[i]([x,bypass])\n        \n        bypass = x\n        x = self.ln2(x)\n        x = self.global_att(x,x)\n        x = self.add3([x,bypass])                \n        \n        bypass = x\n        x = self.ln3(x)\n        x = self.mlp(x)\n        x = self.add3([x,bypass])\n        \n        return x\n\n\nclass DecoderTransformerBlock(layers.Layer):\n    \"\"\"\"\"\"\n    def __init__(self,head_size=head_size, num_heads=num_heads, dropout=dropout, **kwargs):\n        super().__init__(**kwargs)\n        self.support_masking=True\n        self.ln1 = layers.LayerNormalization(center=False)\n        self.ln2 = layers.LayerNormalization(center=False)\n        self.ln3 = layers.LayerNormalization(center=False)\n        self.self_att = layers.MultiHeadAttention(num_heads,head_size,dropout=dropout,use_bias=False)\n        self.cross_att = layers.MultiHeadAttention(num_heads,head_size,dropout=dropout,use_bias=False)\n        self.mlp = MLP(head_size*num_heads)\n        self.add1 = layers.Add()\n        self.add2 = layers.Add()\n        self.add3 = layers.Add()\n        \n    def call(self, x, y):\n        # x is the source sequence (landmarks), y is the target seuqence (phrase)\n        bypass = y\n        y = self.ln1(y)\n        y = self.self_att(y,y,use_causal_mask=True) # Check that self att works out with the double masks\n        y = self.add1([y,bypass])\n              \n        bypass = y \n        y = self.ln2(y)\n        y = self.cross_att(y,x) # Check that cross att works out with the mask of x.\n        y = self.add2([y, bypass])\n        \n        bypass= y \n        y = self.ln3(y)\n        y = self.mlp(y)\n        y = self.add3([y,bypass])\n        \n        return y\n","metadata":{"execution":{"iopub.status.busy":"2023-08-24T17:48:04.405678Z","iopub.execute_input":"2023-08-24T17:48:04.406154Z","iopub.status.idle":"2023-08-24T17:48:04.464784Z","shell.execute_reply.started":"2023-08-24T17:48:04.406118Z","shell.execute_reply":"2023-08-24T17:48:04.463452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OneCycleLR(tf.keras.optimizers.schedules.LearningRateSchedule):\n    \"\"\"Unified single-cycle learning rate scheduler for tensorflow.\n    2022 Hoyeol Sohn <hoeyol0730@gmail.com>\"\"\"\n    def __init__(self, lr=1e-4, epochs=10, steps_per_epoch=100, steps_per_update=1,\n                resume_epoch=0, decay_epochs=10, sustain_epochs=0, warmup_epochs=0,\n                lr_start=0, lr_min=0, warmup_type='linear', decay_type='cosine', **kwargs):\n        \n        super().__init__(**kwargs)\n        self.lr = float(lr)\n        self.epochs = float(epochs)\n        self.steps_per_update = float(steps_per_update)\n        self.resume_step = float(resume_epoch*steps_per_epoch)\n        self.steps_per_epoch = float(steps_per_epoch)\n        self.decay_steps = float(decay_epochs*steps_per_epoch)\n        self.sustain_steps = float(sustain_epochs*steps_per_epoch)\n        self.warmup_steps = float(warmup_epochs*steps_per_epoch)\n        self.total_steps = float(epochs*steps_per_epoch)\n        self.lr_start = float(lr_start)\n        self.lr_min = float(lr_min)\n        self.decay_type = decay_type\n        self.warmup_type = warmup_type\n        \n    def __call__(self, step):\n        step = tf.cast(step, tf.float32)\n        if self.resume_step:\n            step = step + self.resume_step\n\n        step = tf.cond(step > self.decay_steps, lambda :self.decay_steps, lambda :step)\n        step = tf.math.truediv(step, self.steps_per_update) * self.steps_per_update\n\n        warmup_cond = step < self.warmup_steps\n        decay_cond = step >= (self.warmup_steps + self.sustain_steps)\n        \n        if self.warmup_type == 'linear':\n            lr = tf.cond(warmup_cond, lambda: tf.math.divide_no_nan(self.lr-self.lr_start , self.warmup_steps) * step + self.lr_start, lambda: self.lr)\n        elif self.warmup_type == 'exponential':\n            factor = tf.pow(self.lr_start, 1/self.warmup_steps)\n            lr = tf.cond(warmup_cond, lambda: (self.lr - self.lr_start) * factor**(self.warmup_steps - step) + self.lr_start, lambda: self.lr)\n        elif self.warmup_type == 'cosine':\n            lr = tf.cond(warmup_cond, lambda: 0.5 * (self.lr - self.lr_start) * (1 + tf.cos(3.14159265359 * (self.warmup_steps - step)  / self.warmup_steps)) + self.lr_start, lambda:self.lr)\n        else:\n            raise NotImplementedError\n                    \n        if self.decay_type == 'linear':\n            lr = tf.cond(decay_cond, lambda: self.lr + (self.lr_min-self.lr)/(self.decay_steps - self.warmup_steps - self.sustain_steps)*(step - self.warmup_steps - self.sustain_steps), lambda:lr)\n        elif self.decay_type == 'exponential':\n            factor = tf.pow(self.lr_min, 1/(self.decay_steps - self.warmup_steps - self.sustain_steps))\n            lr = tf.cond(decay_cond, lambda: (self.lr - self.lr_min) * factor**(step - self.warmup_steps - self.sustain_steps) + self.lr_min, lambda:lr)\n        elif self.decay_type == 'cosine':\n            lr = tf.cond(decay_cond, lambda: 0.5 * (self.lr - self.lr_min) * (1 + tf.cos(3.14159265359 * (step - self.warmup_steps - self.sustain_steps) / (self.decay_steps - self.warmup_steps - self.sustain_steps))) + self.lr_min, lambda:lr)\n        else:\n            raise NotImplementedError\n        return lr\n\n    def plot(self):\n        step = max(1, int(self.total_steps)//1000) #1 for total_steps < 1000, total_steps//1000 else\n        eps = list(range(0,int(self.total_steps),step))\n        learning_rates = [self(x) for x in eps]\n        eps = [x/self.steps_per_epoch for x in eps]\n        plt.scatter(eps,learning_rates,2)\n        plt.title('Learning rate schedule')\n        plt.xlabel('epochs')\n        plt.ylabel('learning rate')\n        plt.show()    \n\nclass AWP(tf.keras.Model):\n    \"\"\"2022 Hoyeol Sohn <hoeyol0730@gmail.com>\"\"\"\n    def __init__(self, *args, delta=0.1, eps=1e-4, start_step=0, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.delta = delta\n        self.eps = eps\n        self.start_step = start_step\n        \n    def train_step_awp(self, data):\n        # Unpack the data. Its structure depends on your model and\n        # on what you pass to `fit()`.\n        x, y = data\n\n        with tf.GradientTape() as tape:\n            y_pred = self(x, training=True)\n            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n        params = self.trainable_variables\n        params_gradients = tape.gradient(loss, self.trainable_variables)\n        for i in range(len(params_gradients)):\n            grad = tf.zeros_like(params[i]) + params_gradients[i]\n            delta = tf.math.divide_no_nan(self.delta * grad , tf.math.sqrt(tf.reduce_sum(grad**2)) + self.eps)\n            self.trainable_variables[i].assign_add(delta)\n        with tf.GradientTape() as tape2:\n            y_pred = self(x, training=True)\n            new_loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n            if hasattr(self.optimizer, 'get_scaled_loss'):\n                new_loss = self.optimizer.get_scaled_loss(new_loss)\n            \n        gradients = tape2.gradient(new_loss, self.trainable_variables)\n        if hasattr(self.optimizer, 'get_unscaled_gradients'):\n            gradients =  self.optimizer.get_unscaled_gradients(gradients)\n        for i in range(len(params_gradients)):\n            grad = tf.zeros_like(params[i]) + params_gradients[i]\n            delta = tf.math.divide_no_nan(self.delta * grad , tf.math.sqrt(tf.reduce_sum(grad**2)) + self.eps)\n            self.trainable_variables[i].assign_sub(delta)\n        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n        # self_loss.update_state(loss)\n        self.compiled_metrics.update_state(y, y_pred)\n        return {m.name: m.result() for m in self.metrics}\n\n    def train_step(self, data):\n        return tf.cond(self._train_counter < self.start_step, lambda:super(AWP, self).train_step(data), lambda:self.train_step_awp(data))        \n        \ndef masked_loss(label, pred):\n    mask = label != TKPAD\n    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=True, reduction='none')\n    loss = loss_object(label, pred)\n    mask = tf.cast(mask, dtype=loss.dtype)\n    loss *= mask\n    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n    return loss\n\ndef masked_accuracy(label, pred):\n    pred = tf.argmax(pred, axis=2)\n    label = tf.cast(label, pred.dtype)\n    match = label == pred\n    mask = label != TKPAD\n    match = match & mask\n    match = tf.cast(match, dtype=tf.float32)\n    mask = tf.cast(mask, dtype=tf.float32)\n    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-24T17:24:01.551680Z","iopub.execute_input":"2023-08-24T17:24:01.552016Z","iopub.status.idle":"2023-08-24T17:24:01.595279Z","shell.execute_reply.started":"2023-08-24T17:24:01.551988Z","shell.execute_reply":"2023-08-24T17:24:01.594207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\ngc.collect()\ntf.config.optimizer.set_jit(True)\n\nwith strategy.scope():\n# Define model\n    inp1 = layers.Input((MAX_INPUT_LEN,6*NUM_POINTS))\n    inp2 = layers.Input((MAX_OUTPUT_LEN-1,))\n    x = CoordEmbedding()(inp1)\n    y = TokenEmbedding()(inp2)\n    for _ in range(num_enc_layers):\n        x = EncoderTransformerBlock(head_size,num_heads,dropout, kernel_size)(x)\n    for _ in range(num_dec_layers):\n        y = DecoderTransformerBlock(head_size, num_heads, dropout)(x,y)\n    logits = layers.Dense(VOCAB_SIZE)(y)\n    model = tf.keras.Model((inp1,inp2),logits) \n\n    # Define learning rate and weight decay schedule\n    schedule = OneCycleLR(lr, epochs, warmup_epochs=warmup_epochs, steps_per_epoch=steps_per_epoch,\n                      resume_epoch=resume_epoch, decay_epochs=decay_epochs, lr_min=lr_min,\n                      decay_type=decay_type, warmup_type='linear')\n    decay_schedule = OneCycleLR(0.05*lr, epochs, warmup_epochs=warmup_epochs, \n                            steps_per_epoch=steps_per_epoch,\n                            resume_epoch=resume_epoch, decay_epochs=decay_epochs, \n                            lr_min=0.05*lr_min, decay_type=decay_type, warmup_type='linear')\n    # Define optimizers\n    optimizer=tfa.optimizers.RectifiedAdam(learning_rate=schedule,weight_decay=decay_schedule,sma_threshold=4)\n    optimizer=tfa.optimizers.Lookahead(optimizer,sync_period=5)\n\n    model.compile(loss = masked_loss,\n                 optimizer = optimizer,\n                 metrics=[masked_accuracy],\n                 steps_per_execution=steps_per_epoch\n                 )\n    \nmodel.summary()\nschedule.plot()\n\nckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n                filepath='/kaggle/working/'+model_output_name+'.ckpt',\n                save_weights_only=True,\n                monitor='val_masked_accuracy', # Later change to val_norm_levenshtein\n                mode='max',\n                save_best_only=True)\nearly_stop_callback = tf.keras.callbacks.EarlyStopping(\n                monitor='val_masked_accuracy',\n                patience=early_stop_patience,\n                mode='max',\n                start_from_epoch=0)\ncallbacks = [ckpt_callback, early_stop_callback]\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-24T17:48:12.587685Z","iopub.execute_input":"2023-08-24T17:48:12.588069Z","iopub.status.idle":"2023-08-24T17:48:19.490115Z","shell.execute_reply.started":"2023-08-24T17:48:12.588038Z","shell.execute_reply":"2023-08-24T17:48:19.488990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_ds, \n                    epochs = epochs-resume_epoch, \n                    callbacks = callbacks,\n                    validation_data = val_ds,\n                    steps_per_epoch=steps_per_epoch,\n                    validation_steps = val_steps,\n                    verbose = verbose)\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['training loss', 'val_loss'])\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2023-08-24T17:26:27.084147Z","iopub.execute_input":"2023-08-24T17:26:27.084585Z","iopub.status.idle":"2023-08-24T17:27:47.158257Z","shell.execute_reply.started":"2023-08-24T17:26:27.084549Z","shell.execute_reply":"2023-08-24T17:27:47.155346Z"},"trusted":true},"execution_count":null,"outputs":[]}]}